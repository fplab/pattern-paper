\section{Introduction}
\label{sec:intro}

Programming language definitions typically assign meaning to programs only once they are fully-formed and fully-typed. 
However, programming tools---type checkers, language-aware editors, interpreters, program synthesizers, and so on---%
are frequently asked to reason about and manipulate programs that are incomplete or erroneous.
This can occur when the programmer has made a mistake, or when the programmer is simply in the midst of an editing task.
These meaningless states are sometimes transient but they can also persist, e.g. through long refactoring tasks, causing programming tools to flicker out of service or to turn to  
\emph{ad hoc} heuristics, e.g. arbitrary token insertion, or deletion of problematic lines of code, to offer best-effort feedback and assistance \cite{HazelnutSNAPL, DBLP:conf/oopsla/KatsJNV09,DBLP:journals/pacmpl/BourRS18}.
In brief, definitional gaps lead to gaps in service.

In recognition of this pernicious \emph{gap problem}, several programming systems, 
including GHC Haskell \cite{GHCHoles}, Agda \cite{norell:thesis}, Idris \cite{brady2013idris}, and Hazel \cite{DBLP:conf/popl/OmarVHAH17,DBLP:journals/pacmpl/OmarVCH19}, have introduced \emph{typed holes}. Typed holes come in two basic forms: \emph{empty holes} 
stand for terms that have yet to be constructed, and 
\emph{non-empty holes} 
operate as membranes around erroneous terms, e.g. as-yet-type-inconsistent
expressions or as-yet-unbound variables, 
isolating them from the rest of the program.
By incorporating holes into the syntax and semantics, 
it is possible to assign meaning to a greater number of notionally incomplete programs.
Language services can thereby avoid gaps without needing to rely on \emph{ad hoc} heuristics.
Services can also be developed specifically for working with holes. For example, all of the systems mentioned above report  
the expected type and the variables in scope at each hole, and they are also able to synthesize hole fillings in various ways \cite{DBLP:conf/haskell/Gissurarson18,DBLP:journals/pacmpl/LubinCOC20}.

In most of these systems the programmer manually inserts holes where necessary.
Luckily, holes are syntactically lightweight: in GHC Haskell, for example, an unnamed empty expression
hole is simply \li{_}, a named hole is \li{_name}, and non-empty holes can be inserted implicitly around static errors with an appropriate compiler flag. 
In Agda, programmers can express  
non-empty holes explicitly as \li{\{e\}n} where \li{e} is an expression and \li{n} is an identifying hole number.

The Hazel structure editor is distinct in that it inserts both empty and non-empty holes fully automatically during editing.
For example, Fig.~\ref{fig:exhaustiveness}(a), discussed further below, shows an automatically inserted empty hole to the right of the \li{::} operator, numbered \li{98}. Hazel goes on to eliminate the gap problem entirely, maintaining a \emph{maximal liveness invariant}: Hazel assigns both static and dynamic meaning to \emph{every} possible editor state \cite{DBLP:conf/popl/OmarVHAH17, DBLP:journals/pacmpl/OmarVCH19}. This allows Hazel language services to remain fully functional at all
times. This includes services that require program evaluation, because Hazel is capable of evaluating ``around'' 
expression holes, producing \emph{indeterminate results} that retain holes \cite{DBLP:journals/pacmpl/OmarVCH19}. Hazel also supports holes that appear in type annotations, including those where type inference is unable to find a solution, because Hazel is gradually typed \cite{DBLP:conf/snapl/SiekVCB15}. Dynamic type errors (and other dynamic errors) are reformulated as run-time holes to localize their effect on evaluation \cite{DBLP:journals/pacmpl/OmarVCH19}.\footnote{GHC Haskell can also run programs with expression holes, but the program crashes when a hole is reached. It also supports holes in type annotations, but the type inference system must be able to uniquely solve for these holes.}

In all of the systems just described, 
holes can appear in expressions and types.
None of these systems have previously supported holes in patterns. 
Pattern holes would, however, be useful for much the same reason as expression holes are useful: patterns are compositional in structure and are governed by a type discipline.
In Hazel, our focus in this paper, pattern holes are in fact critical to scale up beyond the language in the prior work, which included only binary products and sums with primitive eliminators. Programmers will necessarily construct patterns incrementally\footnote{In Agda, Hazel, and various other systems, the user can automatically generate an exhaustive set of patterns, but these match only on the outermost constructor and involve automatically generated variable names. Programmers often rearrange these incrementally into more deeply nested patterns.} and Hazel must be able to assign meaning to each step to maintain its maximal liveness invariant.

While expressions and types are central to functional programming, patterns are also ubiquitous and pattern holes are far from trivial. Pattern matching can involve both a large number of patterns and individually large and complex patterns. For example, central to the Hazel editor implementation is a single match expression with 68 rules because it matches simultaneously on a pair of values (an action and a state). Several of these patterns have a compositional depth of 5 and span multiple lines of code. Entering individually well-typed patterns and collectively irredundant and exhaustive sequences of patterns in non-trivial programs like this is not always straightforward, and it is easy to make mistakes, e.g. during a non-trivial refactoring. It is also useful to be able to test branches as they become complete, even when many remaining branches remain incomplete. In short, live feedback serves to surface problems as soon as they are certain to occur, rather than in an infrequently batched manner, which helps programmers diagnose problems early and maintain confidence in their mental model of program behavior \cite{tanimoto2013perspective}.

% \todo[inline]{we consider the third outcome of pattern matching, and incorporate it in checking exhaustiveness and redundancy}
This paper describes our integration of full-scale pattern matching (reviewed in Sec.~\ref{sec:background}) with support for pattern holes and live evaluation into Hazel (Sec.~\ref{sec:examples}). We then distill out the essential ideas with a type-theoretic calculus equipped with a system of logical pattern constraints called Peanut, which extends the Hazelnut Live calculus of \citet{DBLP:journals/pacmpl/OmarVCH19} with pattern matching and pattern holes (Sec.~\ref{sec:formalism}). We have mechanized the metatheory of Peanut using Agda (Sec.~\ref{sec:agda} and Supplemental Material). We develop decision procedures in Sec.~\ref{sec:decidability}, describing (1) a simple decision procedure for the necessary logical entailments, and (2) how to express the entailments as an SMT problem for integration into more sophisticated static analyses. To go from Peanut to Hazel, we generalize it to support finite labeled sums, including sums with \emph{datatype constructor holes} (\autoref{sec:labeledsums}). The result, which we integrate into Hazel, produces the first general-purpose functional programming environment that maintains maximal liveness.
% Screenshots of Hazel are used as illustrative examples throughout the paper (link to live demo omitted for anonymous review), though the ideas are applicable more broadly to any language aiming to combine pattern matching and typed holes.

\section{Background}
\label{sec:background}
Before discussing pattern holes, let us briefly review the necessary background and terminology, which will be familiar to users of functional languages. 
Briefly,
\emph{structural pattern matching} combines structural case analysis with destructuring binding. 
Patterns are compositional, so pattern matching can dramatically collapse what would otherwise 
need to be a deeply nested sequence of case analyses and destructurings. The central construct is the \li{match} expression, examples of which appear in  Fig.~\ref{fig:basic-examples}. A match expression consists of a \emph{scrutinee} and an ordered sequence of \li{|}-separated \emph{rules}. Each rule consists of a \emph{pattern} and a \emph{branch expression} separated by \li{->}. The value of the scrutinee is matched against each pattern in order, and if there is a match, the corresponding branch is taken,
with each variable in the pattern bound to the corresponding matched value. The examples in  Fig.~\ref{fig:basic-examples} 
case analyze on the outer constructor of the value of the {scrutinee}, \li{tree}. In cases where the scrutinee was constructed by the application of the \li{Node} constructor, they simultaneously match on the structure of the list argument. Pattern variables and wildcard patterns, \li{_}, match any value, but the latter induces no binding.

\begin{figure}
\begin{subfigure}{.45\textwidth}
\begin{lstlisting}[numbers=none]
match tree
| Node([]) -> Empty
| Node([x]) -> Node([f x, Empty])
| Node([x, y]) -> Node([f x, f y])
| Node(x::y::tl) -> Node(
  [f x, f (Node (y::tl))])
| Leaf x -> Leaf x
| Empty -> Empty
end\end{lstlisting}
\vspace{-6px}
\caption{Exhaustive + Irredundant\label{fig:basic-examples-correct}}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\begin{lstlisting}[numbers=none]
match tree
| Node(x::y::tl) -> Node(
  [f x, f (Node (y::tl))])
| Node([x, y]) -> Node([f x, f y])
| Node([x]) -> Node([f x, Empty])
| Node([]) -> Empty
| Empty -> Empty
end
##\end{lstlisting}
\vspace{-6px}
\caption{Inexhaustive + Redundant (Second Pattern)\label{fig:basic-examples-wrong}}
\end{subfigure}
\vspace{-3px}
\caption{Two examples demonstrating structural pattern matching and common pitfalls.}
\vspace{-4px}
\label{fig:basic-examples}
\end{figure}

Although superficially similar, Fig.~\ref{fig:basic-examples-correct} and Fig.~\ref{fig:basic-examples-wrong}
behave quite differently. In particular, the \li{match} expression in Fig.~\ref{fig:basic-examples-wrong} is \emph{inexhaustive}: there are values of the scrutinee's type, namely values of the form \li{Leaf n}, for which none of the patterns will match, leading to a run-time error or undefined behavior. 
Moreover, the second pattern in Fig.~\ref{fig:basic-examples-wrong} is \emph{redundant}: there are no values that match \li{Node([x, y])} that do not also match some
previous pattern in the rule sequence, here only \li{Node(x::y::tl)}, because \li{[x, y]} is syntactic sugar for \li{x::y::[]}.
%In particular, nodes with exactly two children, e.g. \li{Node([Leaf 1, Leaf 2])}, will match \li{Node(x::y::tl)} because, after desugaring the list literal, we match \li{x} to \li{Leaf 1}, \li{y} to \li{Leaf 2}, and \li{tl} to \li{[]}.
By contrast, Fig.~\ref{fig:basic-examples-correct} has no redundant patterns because \li{Node([x, y])} appears first.
Subtleties like these are easy to miss, particularly for novices but even for experienced programmers when working with complex datatypes.

Fortunately,
modern typed functional languages perform static analyses to detect inexhaustive rule sequences and redundant patterns within a rule sequence.
Exhaustiveness checking compels programmers to consider all possible inputs, including rare cases that may lead to undesirable or undefined behavior. Indeed, many major security issues can be understood as a failure to exhaustively case analyze (e.g. null pointer exceptions).
In the setting of a dependently-typed theorem prover, exhaustiveness checking is necessary to ensure totality and thus logical soundness.
Exhaustiveness checking also supports program evolution: when extending datatype definitions with new constructors, exhaustiveness errors 
serve to alert the programmer of every \li{match} expression that needs to be updated to handle the new case, excepting those that use catch-all wildcard patterns, \li{_} (which for this reason are discouraged in functional programming practice).
Redundancy checking similarly improves software quality by helping programmers avoid subtle order-related bugs and duplicated or unnecessary code paths.


% (Maybe: add gradual typing? add fill-and-resume? add speculative evaluation?)

% (How much to emphasize UI components of Sec 2? Is someone going to ask for a user study??)